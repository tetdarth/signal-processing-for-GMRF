{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 実験概要\n",
    "## CMNによる特徴量抽出\n",
    "**ケプストラム平均正規化** (Cepstrum Mean Normalization : CMN) を使用し、特徴量を抽出する。\n",
    "切り出した波形に対して**離散フーリエ変換** (Discrete Fourier Transform : DFT) を行い、絶対値を取ることで**振幅スペクトル**を得る。\n",
    "これに対して対数を取って**対数振幅スペクトル**に変換し、逆離散フーリエ変換 (Inverse Discrete Fourier Transform : IDFT) を行うことで、ケプストラム領域へと変換し、先頭50要素を切り出し、結合した100要素の配列を前処理として返す。\n",
    "この前処理は\n",
    "```\n",
    "left, right, posture = pp.slicer(\"raw\\\\\" + tester.**.**.value)\n",
    "cepstrum = pp.cmn_denoise(left, right)\n",
    "```\n",
    "によって行われる。\n",
    "\n",
    "## DNNによる寝姿勢分類\n",
    "DNNによって前処理したデータから学習・分類を行う。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モジュールのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "# 自作モジュール\n",
    "import datapath as dpath\n",
    "import preprocess as pp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoaderの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Tuple\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# 標準化 (平均 0 , 分散 1 )\n",
    "def standardization(a, axis=None, ddof=0):\n",
    "    a_mean = a.mean(axis=axis, keepdims=True)\n",
    "    a_std = a.std(axis=axis, keepdims=True, ddof=ddof)\n",
    "    return (a - a_mean) / a_std\n",
    "\n",
    "# 学習用データセットを読み込むためのDataLoaderを定義\n",
    "class train_datasets(Dataset):\n",
    "    def __init__(self, identity, transforms=None):\n",
    "        self.transform = transforms\n",
    "        self.type, self.tester, self.mattress = dpath.getattributes(identity)\n",
    "        print(self.type, self.tester, self.mattress)\n",
    "        print(\"train\")\n",
    "\n",
    "        # テスト以外のrawを読み込む\n",
    "        self.train_cepstrum = np.empty((0, 100))  # 100要素の配列\n",
    "        self.train_posture = np.empty(0)  # 姿勢データ配列\n",
    "\n",
    "        \n",
    "        # mattressに該当するrawのpathを読み込む\n",
    "        # train_paths = eval(f\"dpath.{self.type}.serch('{self.mattress}')\")\n",
    "        \n",
    "        train_paths = []\n",
    "        for mat in dpath.mattress_all():\n",
    "            if mat == self.mattress:\n",
    "                continue\n",
    "            train_paths.extend(eval(f\"dpath.{self.type}.serch('{mat}', skip=[dpath.{self.type}.{self.tester}])\"))\n",
    "        \n",
    "        for p in train_paths:\n",
    "            if identity.value == p:\n",
    "                continue\n",
    "            left, right, posture = pp.slicer(p)\n",
    "            cepstrum = pp.cmn_denoise(left, right)\n",
    "            for cep in cepstrum:\n",
    "                cep = standardization(cep)\n",
    "                self.train_cepstrum = np.vstack((self.train_cepstrum, cep)) if self.train_cepstrum.size else cep\n",
    "            self.train_posture = np.append(self.train_posture, posture) if self.train_posture.size else posture\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_posture)\n",
    "\n",
    "    def __getitem__(self, idx) -> Tuple[torch.tensor, torch.tensor]:\n",
    "        cepstrum = torch.tensor(self.train_cepstrum[idx].reshape(1, -1), dtype=torch.float32)\n",
    "        posture = torch.tensor(self.train_posture[idx]-1, dtype=torch.long)\n",
    "        if self.transform:\n",
    "            cepstrum = self.transform(cepstrum)\n",
    "        return cepstrum, posture\n",
    "\n",
    "\n",
    "# test用データセット\n",
    "class test_datasets(Dataset):\n",
    "    def __init__(self, identity, transform=None):\n",
    "        self.transform = transform\n",
    "        self.type, self.tester, self.mattress = dpath.getattributes(identity)\n",
    "        print(\"test\")\n",
    "\n",
    "        # 前処理したrawを読み込む\n",
    "        self.left, self.right, self.test_posture = pp.slicer(identity.value)\n",
    "        self.test_cepstrum = pp.cmn_denoise(self.left, self.right)\n",
    "        self.test_cepstrum = standardization(self.test_cepstrum)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.test_posture)\n",
    "\n",
    "    def __getitem__(self, idx) -> Tuple[torch.tensor, torch.tensor]:\n",
    "        cepstrum = torch.tensor(self.test_cepstrum[idx].reshape(1, -1), dtype=torch.float32)\n",
    "        posture = torch.tensor(self.test_posture[idx]-1, dtype=torch.long)\n",
    "        if self.transform:\n",
    "            cepstrum = self.transform(cepstrum)\n",
    "        return cepstrum, posture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習＆検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LMH M004 ka\n",
      "train\n",
      "raw\\LMH\\L001\\st_center | data[186 / 208]\n",
      "raw\\LMH\\H003\\st_center | data[340 / 403]\n",
      "raw\\LMH\\M002\\st_center | data[174 / 438]\n",
      "raw\\LMH\\M001\\st_center | data[192 / 324]\n",
      "raw\\LMH\\M003\\st_center | data[220 / 481]\n",
      "raw\\LMH\\H002\\st_center | data[194 / 230]\n",
      "raw\\LMH\\L003\\st_center | data[173 / 208]\n",
      "raw\\LMH\\L001\\fl_center | data[171 / 238]\n",
      "raw\\LMH\\H003\\fl_center | data[204 / 223]\n",
      "raw\\LMH\\M002\\fls_center | data[238 / 427]\n",
      "raw\\LMH\\M002\\flf_center | data[65 / 257]\n",
      "raw\\LMH\\M001\\flf_center | data[89 / 297]\n",
      "raw\\LMH\\M003\\flf_center | data[37 / 178]\n",
      "raw\\LMH\\M002\\fld_center | data[232 / 389]\n",
      "raw\\LMH\\M001\\fls_center | data[190 / 352]\n",
      "raw\\LMH\\M003\\fls_center | data[348 / 642]\n",
      "raw\\LMH\\M003\\fld_center | data[171 / 312]\n",
      "raw\\LMH\\H002\\fl_center | data[212 / 238]\n",
      "raw\\LMH\\M001\\fld_center | data[226 / 444]\n",
      "raw\\LMH\\L003\\fl_center | data[186 / 223]\n",
      "test\n",
      "raw\\LMH\\M004\\ka_left | data[126 / 313]\n"
     ]
    }
   ],
   "source": [
    "# 被験者\n",
    "identity = dpath.LMH.M004.value.ka_left\n",
    "\n",
    "train_val = train_datasets(identity)\n",
    "test = test_datasets(identity)\n",
    "batch_size = 64\n",
    "\n",
    "n_samples = len(train_val)\n",
    "train_size = int(n_samples * 0.8)    # [train : val] を [8 : 2] に分割\n",
    "val_size = n_samples - train_size\n",
    "\n",
    "train, val = torch.utils.data.random_split(train_val, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/100] | train_loss: 1.25443 | train_acc: 0.46004 | val_loss: 0.12025 | val_acc: 0.67013\n",
      "Epoch[2/100] | train_loss: 0.98951 | train_acc: 0.70338 | val_loss: 0.12892 | val_acc: 0.74286\n",
      "Epoch[3/100] | train_loss: 0.84928 | train_acc: 0.75114 | val_loss: 0.07352 | val_acc: 0.76883\n",
      "Epoch[4/100] | train_loss: 0.76699 | train_acc: 0.77713 | val_loss: 0.05419 | val_acc: 0.82727\n",
      "Epoch[5/100] | train_loss: 0.68203 | train_acc: 0.81124 | val_loss: 0.07269 | val_acc: 0.81818\n",
      "Epoch[6/100] | train_loss: 0.61942 | train_acc: 0.85120 | val_loss: 0.05343 | val_acc: 0.83636\n",
      "Epoch[7/100] | train_loss: 0.57077 | train_acc: 0.85900 | val_loss: 0.10163 | val_acc: 0.87143\n",
      "Epoch[8/100] | train_loss: 0.52933 | train_acc: 0.87037 | val_loss: 0.04903 | val_acc: 0.86753\n",
      "Epoch[9/100] | train_loss: 0.48626 | train_acc: 0.88304 | val_loss: 0.04110 | val_acc: 0.89610\n",
      "Epoch[10/100] | train_loss: 0.45682 | train_acc: 0.89896 | val_loss: 0.02929 | val_acc: 0.88831\n",
      "Epoch[11/100] | train_loss: 0.41545 | train_acc: 0.91293 | val_loss: 0.14663 | val_acc: 0.90260\n",
      "Epoch[12/100] | train_loss: 0.40030 | train_acc: 0.91813 | val_loss: 0.08024 | val_acc: 0.90909\n",
      "Epoch[13/100] | train_loss: 0.37162 | train_acc: 0.92105 | val_loss: 0.08211 | val_acc: 0.91039\n",
      "Epoch[14/100] | train_loss: 0.33496 | train_acc: 0.92820 | val_loss: 0.04954 | val_acc: 0.91818\n",
      "Epoch[15/100] | train_loss: 0.32360 | train_acc: 0.93437 | val_loss: 0.04363 | val_acc: 0.91948\n",
      "Epoch[16/100] | train_loss: 0.30450 | train_acc: 0.93665 | val_loss: 0.05905 | val_acc: 0.92208\n",
      "Epoch[17/100] | train_loss: 0.28790 | train_acc: 0.94574 | val_loss: 0.03816 | val_acc: 0.93506\n",
      "Epoch[18/100] | train_loss: 0.28107 | train_acc: 0.94412 | val_loss: 0.12053 | val_acc: 0.92727\n",
      "Epoch[19/100] | train_loss: 0.26073 | train_acc: 0.94444 | val_loss: 0.01925 | val_acc: 0.92987\n",
      "Epoch[20/100] | train_loss: 0.24600 | train_acc: 0.95257 | val_loss: 0.11358 | val_acc: 0.92727\n",
      "Epoch[21/100] | train_loss: 0.24058 | train_acc: 0.95159 | val_loss: 0.04888 | val_acc: 0.93766\n",
      "Epoch[22/100] | train_loss: 0.22353 | train_acc: 0.95939 | val_loss: 0.04226 | val_acc: 0.93247\n",
      "Epoch[23/100] | train_loss: 0.20366 | train_acc: 0.96394 | val_loss: 0.05314 | val_acc: 0.93117\n",
      "Epoch[24/100] | train_loss: 0.21161 | train_acc: 0.96069 | val_loss: 0.18096 | val_acc: 0.93896\n",
      "Epoch[25/100] | train_loss: 0.20159 | train_acc: 0.96719 | val_loss: 0.03549 | val_acc: 0.94675\n",
      "Epoch[26/100] | train_loss: 0.18601 | train_acc: 0.96849 | val_loss: 0.04067 | val_acc: 0.93896\n",
      "Epoch[27/100] | train_loss: 0.18670 | train_acc: 0.96036 | val_loss: 0.11939 | val_acc: 0.94026\n",
      "Epoch[28/100] | train_loss: 0.17614 | train_acc: 0.96849 | val_loss: 0.03625 | val_acc: 0.96234\n",
      "Epoch[29/100] | train_loss: 0.16905 | train_acc: 0.97238 | val_loss: 0.11146 | val_acc: 0.94545\n",
      "Epoch[30/100] | train_loss: 0.16933 | train_acc: 0.96881 | val_loss: 0.02735 | val_acc: 0.94545\n",
      "Epoch[31/100] | train_loss: 0.15763 | train_acc: 0.97368 | val_loss: 0.13346 | val_acc: 0.94675\n",
      "Epoch[32/100] | train_loss: 0.15238 | train_acc: 0.97303 | val_loss: 0.13446 | val_acc: 0.96623\n",
      "Epoch[33/100] | train_loss: 0.14356 | train_acc: 0.97498 | val_loss: 0.02310 | val_acc: 0.94805\n",
      "Epoch[34/100] | train_loss: 0.14282 | train_acc: 0.97693 | val_loss: 0.10824 | val_acc: 0.95195\n",
      "Epoch[35/100] | train_loss: 0.13412 | train_acc: 0.97758 | val_loss: 0.07560 | val_acc: 0.95065\n",
      "Epoch[36/100] | train_loss: 0.14173 | train_acc: 0.97498 | val_loss: 0.17624 | val_acc: 0.95714\n",
      "Epoch[37/100] | train_loss: 0.13383 | train_acc: 0.97466 | val_loss: 0.02478 | val_acc: 0.94805\n",
      "Epoch[38/100] | train_loss: 0.12402 | train_acc: 0.97986 | val_loss: 0.14083 | val_acc: 0.96494\n",
      "Epoch[39/100] | train_loss: 0.12603 | train_acc: 0.97628 | val_loss: 0.01907 | val_acc: 0.96104\n",
      "Epoch[40/100] | train_loss: 0.12128 | train_acc: 0.98116 | val_loss: 0.19484 | val_acc: 0.95325\n",
      "Epoch[41/100] | train_loss: 0.11457 | train_acc: 0.98376 | val_loss: 0.05577 | val_acc: 0.94805\n",
      "Epoch[42/100] | train_loss: 0.11624 | train_acc: 0.98083 | val_loss: 0.09661 | val_acc: 0.96234\n",
      "Epoch[43/100] | train_loss: 0.11498 | train_acc: 0.97921 | val_loss: 0.17295 | val_acc: 0.95455\n",
      "Epoch[44/100] | train_loss: 0.10347 | train_acc: 0.98343 | val_loss: 0.02652 | val_acc: 0.94935\n",
      "Epoch[45/100] | train_loss: 0.10385 | train_acc: 0.98538 | val_loss: 0.15994 | val_acc: 0.95195\n",
      "Epoch[46/100] | train_loss: 0.09790 | train_acc: 0.98506 | val_loss: 0.18028 | val_acc: 0.95455\n",
      "Epoch[47/100] | train_loss: 0.09784 | train_acc: 0.98603 | val_loss: 0.00770 | val_acc: 0.95974\n",
      "Epoch[48/100] | train_loss: 0.09501 | train_acc: 0.98733 | val_loss: 0.01162 | val_acc: 0.95325\n",
      "Epoch[49/100] | train_loss: 0.09051 | train_acc: 0.98863 | val_loss: 0.03340 | val_acc: 0.95844\n",
      "Epoch[50/100] | train_loss: 0.08555 | train_acc: 0.98765 | val_loss: 0.09762 | val_acc: 0.96883\n",
      "Epoch[51/100] | train_loss: 0.08560 | train_acc: 0.98473 | val_loss: 0.16208 | val_acc: 0.95714\n",
      "Epoch[52/100] | train_loss: 0.08194 | train_acc: 0.98506 | val_loss: 0.02205 | val_acc: 0.96623\n",
      "Epoch[53/100] | train_loss: 0.08932 | train_acc: 0.98668 | val_loss: 0.02306 | val_acc: 0.95974\n",
      "Epoch[54/100] | train_loss: 0.08456 | train_acc: 0.98830 | val_loss: 0.02067 | val_acc: 0.97273\n",
      "Epoch[55/100] | train_loss: 0.08652 | train_acc: 0.98668 | val_loss: 0.05197 | val_acc: 0.96364\n",
      "Epoch[56/100] | train_loss: 0.07891 | train_acc: 0.98765 | val_loss: 0.06909 | val_acc: 0.95844\n",
      "Epoch[57/100] | train_loss: 0.07638 | train_acc: 0.98733 | val_loss: 0.00677 | val_acc: 0.96494\n",
      "Epoch[58/100] | train_loss: 0.07593 | train_acc: 0.98895 | val_loss: 0.02574 | val_acc: 0.96364\n",
      "Epoch[59/100] | train_loss: 0.06581 | train_acc: 0.99415 | val_loss: 0.05402 | val_acc: 0.96234\n",
      "Epoch[60/100] | train_loss: 0.06925 | train_acc: 0.99123 | val_loss: 0.02310 | val_acc: 0.95974\n",
      "Epoch[61/100] | train_loss: 0.06984 | train_acc: 0.99058 | val_loss: 0.05229 | val_acc: 0.96753\n",
      "Epoch[62/100] | train_loss: 0.07427 | train_acc: 0.98830 | val_loss: 0.15418 | val_acc: 0.95974\n",
      "Epoch[63/100] | train_loss: 0.05990 | train_acc: 0.99318 | val_loss: 0.10388 | val_acc: 0.96883\n",
      "Epoch[64/100] | train_loss: 0.07335 | train_acc: 0.98895 | val_loss: 0.08980 | val_acc: 0.96494\n",
      "Epoch[65/100] | train_loss: 0.07196 | train_acc: 0.99220 | val_loss: 0.04237 | val_acc: 0.96364\n",
      "Epoch[66/100] | train_loss: 0.06796 | train_acc: 0.99188 | val_loss: 0.03001 | val_acc: 0.96753\n",
      "Epoch[67/100] | train_loss: 0.05716 | train_acc: 0.99253 | val_loss: 0.01623 | val_acc: 0.97143\n",
      "Epoch[68/100] | train_loss: 0.05394 | train_acc: 0.99480 | val_loss: 0.02323 | val_acc: 0.96494\n",
      "Epoch[69/100] | train_loss: 0.05269 | train_acc: 0.99448 | val_loss: 0.06539 | val_acc: 0.96883\n",
      "Epoch[70/100] | train_loss: 0.06301 | train_acc: 0.99220 | val_loss: 0.03946 | val_acc: 0.96623\n",
      "Epoch[71/100] | train_loss: 0.06215 | train_acc: 0.99383 | val_loss: 0.01482 | val_acc: 0.96623\n",
      "Epoch[72/100] | train_loss: 0.05649 | train_acc: 0.99318 | val_loss: 0.16450 | val_acc: 0.95714\n",
      "Epoch[73/100] | train_loss: 0.05239 | train_acc: 0.99350 | val_loss: 0.00876 | val_acc: 0.97403\n",
      "Epoch[74/100] | train_loss: 0.04901 | train_acc: 0.99318 | val_loss: 0.03097 | val_acc: 0.97013\n",
      "Epoch[75/100] | train_loss: 0.05232 | train_acc: 0.99545 | val_loss: 0.11759 | val_acc: 0.96234\n",
      "Epoch[76/100] | train_loss: 0.05681 | train_acc: 0.99415 | val_loss: 0.17871 | val_acc: 0.96364\n",
      "Epoch[77/100] | train_loss: 0.05011 | train_acc: 0.99383 | val_loss: 0.01024 | val_acc: 0.97013\n",
      "Epoch[78/100] | train_loss: 0.05734 | train_acc: 0.99123 | val_loss: 0.01275 | val_acc: 0.97273\n",
      "Epoch[79/100] | train_loss: 0.05206 | train_acc: 0.99285 | val_loss: 0.05453 | val_acc: 0.96494\n",
      "Epoch[80/100] | train_loss: 0.04833 | train_acc: 0.99350 | val_loss: 0.08054 | val_acc: 0.96623\n",
      "Epoch[81/100] | train_loss: 0.04859 | train_acc: 0.99513 | val_loss: 0.01001 | val_acc: 0.97403\n",
      "Epoch[82/100] | train_loss: 0.04508 | train_acc: 0.99415 | val_loss: 0.01239 | val_acc: 0.96753\n",
      "Epoch[83/100] | train_loss: 0.04530 | train_acc: 0.99383 | val_loss: 0.00608 | val_acc: 0.96753\n",
      "Epoch[84/100] | train_loss: 0.04977 | train_acc: 0.99448 | val_loss: 0.01022 | val_acc: 0.97532\n",
      "Epoch[85/100] | train_loss: 0.04425 | train_acc: 0.99415 | val_loss: 0.01825 | val_acc: 0.97273\n",
      "Epoch[86/100] | train_loss: 0.04267 | train_acc: 0.99578 | val_loss: 0.01410 | val_acc: 0.96364\n",
      "Epoch[87/100] | train_loss: 0.04667 | train_acc: 0.99383 | val_loss: 0.12687 | val_acc: 0.95974\n",
      "Epoch[88/100] | train_loss: 0.04651 | train_acc: 0.99383 | val_loss: 0.01278 | val_acc: 0.96104\n",
      "Epoch[89/100] | train_loss: 0.04644 | train_acc: 0.99285 | val_loss: 0.02678 | val_acc: 0.96494\n",
      "Epoch[90/100] | train_loss: 0.04288 | train_acc: 0.99740 | val_loss: 0.08829 | val_acc: 0.97013\n",
      "Epoch[91/100] | train_loss: 0.04707 | train_acc: 0.99643 | val_loss: 0.16544 | val_acc: 0.97143\n",
      "Epoch[92/100] | train_loss: 0.04242 | train_acc: 0.99480 | val_loss: 0.09367 | val_acc: 0.96623\n",
      "Epoch[93/100] | train_loss: 0.04139 | train_acc: 0.99773 | val_loss: 0.01487 | val_acc: 0.96364\n",
      "Epoch[94/100] | train_loss: 0.04360 | train_acc: 0.99480 | val_loss: 0.01645 | val_acc: 0.97013\n",
      "Epoch[95/100] | train_loss: 0.04200 | train_acc: 0.99545 | val_loss: 0.01115 | val_acc: 0.97013\n",
      "Epoch[96/100] | train_loss: 0.04120 | train_acc: 0.99675 | val_loss: 0.02708 | val_acc: 0.97662\n",
      "Epoch[97/100] | train_loss: 0.04638 | train_acc: 0.99513 | val_loss: 0.02416 | val_acc: 0.96883\n",
      "Epoch[98/100] | train_loss: 0.04123 | train_acc: 0.99610 | val_loss: 0.04929 | val_acc: 0.96883\n",
      "Epoch[99/100] | train_loss: 0.04241 | train_acc: 0.99480 | val_loss: 0.19074 | val_acc: 0.97273\n",
      "Epoch[100/100] | train_loss: 0.04048 | train_acc: 0.99448 | val_loss: 0.01754 | val_acc: 0.96883\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import model_resnet as resnet\n",
    "import model_har as har\n",
    "\n",
    "# モデルのインスタンス化\n",
    "net = har.HAR(num_classes=4).to(device)\n",
    "\n",
    "# 誤差関数を交差エントロピーで計算\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 最適化アルゴリズム\n",
    "optimizer = optim.SGD(net.parameters(), lr = 1e-5, momentum=0.9)\n",
    "\n",
    "# 学習\n",
    "n_epoch = 100\n",
    "for epoch in range(n_epoch):\n",
    "    # 精度と損失の初期化\n",
    "    train_acc, train_loss = 0, 0\n",
    "    val_acc, val_loss = 0, 0\n",
    "    n_train, n_val = 0, 0\n",
    "\n",
    "    # 学習\n",
    "    for train_input, train_label in train_loader:\n",
    "        n_train += len(train_label)\n",
    "\n",
    "        # 入力と正解ラベルをGPU上に移動\n",
    "        input = train_input.to(device)\n",
    "        label = train_label.to(device)\n",
    "        # print(f'input : {input.shape}, label : {label.shape}')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = net(input)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        predicted = torch.max(output, 1)[1]\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_acc += (predicted == label).sum().item()\n",
    "\n",
    "    # 検証\n",
    "    for val_input, val_label in val_loader:\n",
    "        n_val += len(val_label)\n",
    "\n",
    "        val_input = val_input.to(device)\n",
    "        val_label = val_label.to(device)\n",
    "\n",
    "        val_output = net(val_input)\n",
    "        val_loss = criterion(val_output, val_label)\n",
    "\n",
    "        val_predicted = torch.max(val_output, 1)[1]\n",
    "\n",
    "        val_loss += val_loss.item()\n",
    "        val_acc += (val_predicted == val_label).sum().item()\n",
    "\n",
    "    # 精度を確率に変換\n",
    "    train_acc /= n_train\n",
    "    val_acc /= n_val\n",
    "    train_loss = train_loss * batch_size / n_train\n",
    "    val_loss = val_loss * batch_size / n_val\n",
    "\n",
    "    if not epoch%1:\n",
    "        print(f\"Epoch[{epoch+1}/{n_epoch}] | train_loss: {train_loss:.5f} | train_acc: {train_acc:.5f} | val_loss: {val_loss:.5f} | val_acc: {val_acc:.5f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss : 0.53599, acc : 0.35714\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = 0, 0\n",
    "n_test = 0\n",
    "\n",
    "for test_input, test_label in test_loader:\n",
    "        n_test += len(test_label)\n",
    "\n",
    "        test_input = test_input.to(device)\n",
    "        test_label = test_label.to(device)\n",
    "\n",
    "        test_output = net(test_input)\n",
    "        test_loss = criterion(test_output, test_label)\n",
    "\n",
    "        test_predicted = torch.max(test_output, 1)[1]\n",
    "\n",
    "        test_loss += test_loss.item()\n",
    "        test_acc += (test_predicted == test_label).sum().item()\n",
    "        \n",
    "# 精度を確率に変換\n",
    "test_acc /= n_test\n",
    "test_loss = test_loss * batch_size / n_test\n",
    "\n",
    "print(f\"loss : {test_loss:.5f}, acc : {test_acc:.5f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
