{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 実験概要\n",
    "## CMNによる特徴量抽出\n",
    "**ケプストラム平均正規化** (Cepstrum Mean Normalization : CMN) を使用し、特徴量を抽出する。\n",
    "切り出した波形に対して**離散フーリエ変換** (Discrete Fourier Transform : DFT) を行い、絶対値を取ることで**振幅スペクトル**を得る。\n",
    "これに対して対数を取って**対数振幅スペクトル**に変換し、逆離散フーリエ変換 (Inverse Discrete Fourier Transform : IDFT) を行うことで、ケプストラム領域へと変換し、先頭50要素を切り出し、結合した100要素の配列を前処理として返す。\n",
    "この前処理は\n",
    "```\n",
    "left, right, posture = pp.slicer(\"raw\\\\\" + tester.**.**.value)\n",
    "cepstrum = pp.cmn_denoise(left, right)\n",
    "```\n",
    "によって行われる。\n",
    "\n",
    "## DNNによる寝姿勢分類\n",
    "DNNによって前処理したデータから学習・分類を行う。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モジュールのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# 自作モジュール\n",
    "import data_path as dpath\n",
    "import preprocess as pp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoaderの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tester以外のrawを読み込む\n",
    "for p in glob.glob(\".\\\\raw\\\\LMH\\\\*\\\\\", recursive=True):\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習用データセットを読み込むためのDataLoaderを定義\n",
    "class train_datasets(Dataset):\n",
    "    def __init__(self, type, mat, tester, transforms=None):\n",
    "        self.type = type\n",
    "        self.mat = mat\n",
    "        self.tester = tester\n",
    "        self.transform = transforms\n",
    "\n",
    "        # tester以外のrawを読み込む\n",
    "        self.train_cep = np.empty((0, 100))  # 100要素の配列\n",
    "        self.train_posture = np.empty(0) # 姿勢データ配列\n",
    "        self.tester_path = dpath.get_path(type, mat, tester)\n",
    "        for p in glob.glob(\".\\\\raw\\\\LMH\\\\*\\\\\", recursive=True):\n",
    "            for tpath in self.tester_path:\n",
    "                if p == tpath:\n",
    "                    continue\n",
    "            left, right, posture = pp.slicer(p)\n",
    "            cep = pp.cmn_denoise(left, right)\n",
    "            self.train_cep = np.vstack(self.train_cep, cep)\n",
    "            self.train_posture = np.hstack(posture)\n",
    "        print(self.train_cep.shape, self.train_posture.shape)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_datasets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.train_datasets[idx]\n",
    "\n",
    "class test_datasets(Dataset):\n",
    "    def __init__(self, tester, transform=None):\n",
    "        self.tester = tester.value\n",
    "        self.transform = transform\n",
    "\n",
    "        # 前処理したrawを読み込む\n",
    "        self.left, self.right, self.posture = pp.slicer(\"raw\\\\\"+self.csv_file)\n",
    "        self.cepstrum = pp.cmn_denoise(self.left, self.right)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.cepstrum)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.cepstrum[idx], self.posture[idx]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
